{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGP 5 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "1. import files into dataframe\n",
    "2. extract 'full' days (1440 rows per date)\n",
    "3. extract number of days matching scores.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load functions in python file with magic command\n",
    "%run ../code/preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "folderpath = '../depresjon'\n",
    "output_csv_path = '../output/'\n",
    "scores_csv_path = '../depresjon/scores.csv'\n",
    "\n",
    "# extract files\n",
    "df = extract_from_folder(folderpath)\n",
    "\n",
    "# extract full days (true days)\n",
    "full_df = preprocess_full_days(df)\n",
    "\n",
    "# extract days per scores \n",
    "final = extract_days_per_scores(full_df, scores_csv_path)\n",
    "\n",
    "# pivot df to wide format\n",
    "final_pivot = pivot_dataframe(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "final_pivot.to_csv(output_csv_path + 'preprocessed-wide.csv', index=False)\n",
    "final.to_csv(output_csv_path+ 'preprocessed-long.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variable names to delete\n",
    "var_list = ['df', 'full_df',  'final', 'final_pivot']\n",
    "\n",
    "# loop over the list and delete variables if they exist\n",
    "for var in var_list:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "* Kept all id, date combinations to maximise data\n",
    "* will split into train, test, val\n",
    "* will keep proportions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To calculate the features: \n",
    "\n",
    "* **Day / Night** - determined by hours, e.g. 08:00-20:00\n",
    "\n",
    "$\\text{{day\\_night}} = \\begin{cases} \n",
    "0 & \\text{{if }} \\text{{day\\_start}} \\leq \\text{{hour}} < \\text{{day\\_end}} \\\\\n",
    "1 & \\text{{otherwise}}\n",
    "\\end{cases}$\n",
    "\n",
    "* **Light / Dark** - determined by monthly sunset/sunrise times in Norway\n",
    "\n",
    "$\\text{{light\\_dark}} = \\begin{cases} \n",
    "0 & \\text{{if }} \\text{{sunrise\\_time}} \\leq \\text{{timestamp}} < \\text{{sunset\\_time}} \\\\\n",
    "1 & \\text{{otherwise}}\n",
    "\\end{cases}$\n",
    "\n",
    "\n",
    "* **Active / Inactive** - active is where the rolling average (window = 11) of 'active minute' (`activity threshold` > 5) is greater than `rolling threshold` (2)\n",
    "\n",
    "$\\text{{active\\_inactive}} = \\begin{cases} \n",
    "1 & \\text{{if }} \\text{{activity}} \\geq \\text{{activity\\_threshold}} \\\\\n",
    "0 & \\text{{otherwise}}\n",
    "\\end{cases}$\n",
    "\n",
    "$\\text{{rolling\\_sum}} = \\text{{rolling sum of }} \\text{{active\\_inactive}} \\text{{ over a window of }} \\text{{rolling\\_window}}$\n",
    "\n",
    "$\\text{{active\\_inactive\\_period}} = \\begin{cases} \n",
    "1 & \\text{{if }} \\text{{rolling\\_sum}} \\geq \\text{{rolling\\_threshold}} \\\\\n",
    "0 & \\text{{otherwise}}\n",
    "\\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    ">all row level, therfore no data leakage - that is features are computed separately for each (id, date) combination so that there is no data leakage / contamination\n",
    "\n",
    "\n",
    "* **inactiveDay**: The proportion of time during the day when the participant is inactive.\n",
    "\n",
    "$\\text{{inactiveDay}} = \\frac{{\\text{{Number of inactive hours during the day}}}}{{\\text{{Total number of hours during the day}}}}$\n",
    "\n",
    "\n",
    "* **activeNight**: The proportion of time during the night when the participant is active.\n",
    "\n",
    "$\\text{{activeNight}} = \\frac{{\\text{{Number of active hours during the night}}}}{{\\text{{Total number of hours during the night}}}}$\n",
    "\n",
    "* **inactiveLight**: The proportion of time during periods of light (e.g., daytime) when the participant is inactive.\n",
    "\n",
    "$\\text{{inactiveLight}} = \\frac{{\\text{{Number of inactive hours during periods of light}}}}{{\\text{{Total number of hours during periods of light}}}}\n",
    "$\n",
    "\n",
    "\n",
    "* **activeDark**: The proportion of time during periods of darkness (e.g., nighttime) when the participant is active.\n",
    "\n",
    "$\\text{{activeDark}} = \\frac{{\\text{{Number of active hours during periods of darkness}}}}{{\\text{{Total number of hours during periods of darkness}}}}$\n",
    "\n",
    "\n",
    "* **mean**: The average value of activity data for each hour of the day. It represents the central tendency of the data.\n",
    "\n",
    "$\\text{{mean}}_{\\text{{person-date}}} = \\frac{{\\sum_{i=1}^{n} \\text{{activity}}_{\\text{{person-date}}}(i)}}{{n}}$\n",
    "\n",
    "\n",
    "* **std**: The standard deviation of activity data for each hour of the day. It measures the dispersion or spread of the data around the mean.\n",
    "\n",
    "$\\text{{std}}_{\\text{{person-date}}} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (\\text{{activity}}_{\\text{{person-date}}}(i) - \\text{{mean}}_{\\text{{person-date}}})^2}$\n",
    "\n",
    "\n",
    "* **percentZero**: The percentage of data points that have a value of zero for each hour of the day.\n",
    "\n",
    "$\\text{{percent\\_zero}}_{\\text{{person-date}}} = \\frac{{\\text{{Number of hours with zero activity}}_{\\text{{person-date}}}}}{{\\text{{Total number of hours}}_{\\text{{person-date}}}}} \\times 100$\n",
    "\n",
    "\n",
    "* **kurtosis**: A measure of the \"tailedness\" or shape of a distribution. It indicates how sharply peaked or flat the distribution is compared to a normal distribution. Positive kurtosis indicates a relatively peaked distribution, while negative kurtosis indicates a relatively flat distribution.\n",
    "\n",
    "$\\text{{kurtosis}}_{\\text{{person-date}}} = \\frac{{\\frac{1}{n} \\sum_{i=1}^{n} (\\text{{activity}}_{\\text{{person-date}}}(i) - \\text{{mean}}_{\\text{{person-date}}})^4}}{{\\left( \\frac{1}{n} \\sum_{i=1}^{n} (\\text{{activity}}_{\\text{{person-date}}}(i) - \\text{{mean}}_{\\text{{person-date}}})^2 \\right)^2}}$\n",
    "\n",
    "* **median**: The middle value in the sorted list of values.\n",
    "\n",
    "$\\text{median}_{\\text{person-date}} = \n",
    "\\begin{cases} \n",
    "\\text{activity}_{\\text{person-date}}\\left(\\frac{n+1}{2}\\right) & \\text{if } n \\text{ is odd} \\\\\n",
    "\\frac{1}{2} \\left( \\text{activity}_{\\text{person-date}}\\left(\\frac{n}{2}\\right) + \\text{activity}_{\\text{person-date}}\\left(\\frac{n}{2} + 1\\right) \\right) & \\text{if } n \\text{ is even}\n",
    "\\end{cases}$\n",
    "\n",
    "* **first quartile (0.25)**: The value below which 25% of values fall.\n",
    "\n",
    "$\\text{{Q1}}_{\\text{{person-date}}} = \\text{{activity}}_{\\text{{person-date}}}\\left(\\frac{n+1}{4}\\right)$\n",
    "\n",
    "* **third quartile (0.75)**: The value below which 75% of values fall.\n",
    "\n",
    "$\\text{{Q3}}_{\\text{{person-date}}} = \\text{{activity}}_{\\text{{person-date}}}\\left(\\frac{3(n+1)}{4}\\right)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "1. [x] calculate row-level independent features (participant-day) on whole dataset\n",
    "2. [x] split into male, female, both datasets\n",
    "3. [x] split each into train and validate datasets\n",
    "4. [x] normalise male, female, both train sets\n",
    "5. [x] normalise validation sets with respective parameters from train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "output_csv_path = '../output/'\n",
    "scores_csv_path = '../depresjon/scores.csv'\n",
    "\n",
    "# import from csv\n",
    "df = pd.read_csv(output_csv_path + 'preprocessed-long.csv', parse_dates=['timestamp', 'date'])\n",
    "\n",
    "# load functions in python file with magic command\n",
    "%run ../code/features.py\n",
    "%run ../code/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Female, Male, Both datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate features\n",
    "features_full = calculate_all_features(df, sunlight_df)\n",
    "# save to csv\n",
    "features_full.to_csv(output_csv_path + 'features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Female, Male, Both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male dataset shape: (310, 12)\n",
      "Female dataset shape: (383, 12)\n",
      "Both genders dataset shape: (693, 12)\n"
     ]
    }
   ],
   "source": [
    "male, female, both = split_and_prepare_data(features_full)\n",
    "\n",
    "# shapes of the datasets \n",
    "print(f\"Male dataset shape: {male.shape}\")\n",
    "print(f\"Female dataset shape: {female.shape}\")\n",
    "print(f\"Both genders dataset shape: {both.shape}\")\n",
    "\n",
    "# save to csv\n",
    "male.to_csv(output_csv_path + 'male.csv', index=False)\n",
    "female.to_csv(output_csv_path + 'female.csv', index=False)\n",
    "both.to_csv(output_csv_path + 'both.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Train and Validate sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male shapes: (263, 11), (47, 11), (263,), (47,)\n",
      "Female shapes: (325, 11), (58, 11), (325,), (58,) \n",
      "Both shapes: (589, 11), (104, 11), (589,), (104,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and validate\n",
    "male_X_train, male_X_valid, male_y_train, male_y_valid = validation_data(male)\n",
    "female_X_train, female_X_valid, female_y_train, female_y_valid = validation_data(female)\n",
    "both_X_train, both_X_valid, both_y_train, both_y_valid = validation_data(both)\n",
    "\n",
    "# shapes of the datasets\n",
    "print(f\"Male shapes: {male_X_train.shape}, {male_X_valid.shape}, {male_y_train.shape}, {male_y_valid.shape}\")\n",
    "print(f\"Female shapes: {female_X_train.shape}, {female_X_valid.shape}, {female_y_train.shape}, {female_y_valid.shape} \")\n",
    "print(f\"Both shapes: {both_X_train.shape}, {both_X_valid.shape}, {both_y_train.shape}, {both_y_valid.shape}\")  \n",
    "\n",
    "# save to csv\n",
    "male_X_train.to_csv(output_csv_path + 'male_X_train.csv', index=False)\n",
    "male_X_valid.to_csv(output_csv_path + 'male_X_valid.csv', index=False)\n",
    "male_y_train.to_csv(output_csv_path + 'male_y_train.csv', index=False)\n",
    "male_y_valid.to_csv(output_csv_path + 'male_y_valid.csv', index=False)\n",
    "female_X_train.to_csv(output_csv_path + 'female_X_train.csv', index=False)\n",
    "female_X_valid.to_csv(output_csv_path + 'female_X_valid.csv', index=False)\n",
    "female_y_train.to_csv(output_csv_path + 'female_y_train.csv', index=False)\n",
    "female_y_valid.to_csv(output_csv_path + 'female_y_valid.csv', index=False)\n",
    "both_X_train.to_csv(output_csv_path + 'both_X_train.csv', index=False)\n",
    "both_X_valid.to_csv(output_csv_path + 'both_X_valid.csv', index=False)\n",
    "both_y_train.to_csv(output_csv_path + 'both_y_train.csv', index=False)\n",
    "both_y_valid.to_csv(output_csv_path + 'both_y_valid.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise Train and Validate Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise train, apply to train and val\n",
    "male_X_train_scaled, male_X_valid_scaled = normalise_data(male_X_train, male_X_valid)\n",
    "female_X_train_scaled, female_X_valid_scaled = normalise_data(female_X_train, female_X_valid)\n",
    "both_X_train_scaled, both_X_valid_scaled = normalise_data(both_X_train, both_X_valid)\n",
    "\n",
    "# save to csv\n",
    "male_X_train_scaled.to_csv(output_csv_path + 'male_X_train_scaled.csv', index=False)\n",
    "male_X_valid_scaled.to_csv(output_csv_path + 'male_X_valid_scaled.csv', index=False)\n",
    "female_X_train_scaled.to_csv(output_csv_path + 'female_X_train_scaled.csv', index=False)\n",
    "female_X_valid_scaled.to_csv(output_csv_path + 'female_X_valid_scaled.csv', index=False)\n",
    "both_X_train_scaled.to_csv(output_csv_path + 'both_X_train_scaled.csv', index=False)\n",
    "both_X_valid_scaled.to_csv(output_csv_path + 'both_X_valid_scaled.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igp5_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
