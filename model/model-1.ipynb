{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGP 5 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "1. import files into dataframe\n",
    "2. extract 'full' days (1440 rows per date)\n",
    "3. extract number of days matching scores.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load functions in python file with magic command\n",
    "%run ../code/preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "folderpath = '../depresjon'\n",
    "output_csv_path = '../output/'\n",
    "scores_csv_path = '../depresjon/scores.csv'\n",
    "\n",
    "# extract files\n",
    "df = extract_from_folder(folderpath)\n",
    "\n",
    "# extract full days (true days)\n",
    "full_df = preprocess_full_days(df)\n",
    "\n",
    "# extract days per scores \n",
    "final = extract_days_per_scores(full_df, scores_csv_path)\n",
    "\n",
    "# pivot df to wide format\n",
    "final_pivot = pivot_dataframe(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "final_pivot.to_csv(output_csv_path + 'preprocessed-wide.csv', index=False)\n",
    "final.to_csv(output_csv_path+ 'preprocessed-long.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variable names to delete\n",
    "var_list = ['df', 'full_df',  'final', 'final_pivot']\n",
    "\n",
    "# loop over the list and delete variables if they exist\n",
    "for var in var_list:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "* Kept all id, date combinations to maximise data\n",
    "* will split into train, test, val\n",
    "* will keep proportions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import from CSV\n",
    "\n",
    "1. import preprocessed csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "output_csv_path = '../output/'\n",
    "scores_csv_path = '../depresjon/scores.csv'\n",
    "\n",
    "# import from csv\n",
    "df = pd.read_csv(output_csv_path + 'preprocessed-long.csv', parse_dates=['timestamp', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    ">all row level, therfore no data leakage\n",
    "\n",
    "TODO - describe features\n",
    "\n",
    "* inactiveDa\n",
    "* activeNight\n",
    "* inactiveLight\n",
    "* activeDark\n",
    "* mean\n",
    "* std\n",
    "* percentZero\n",
    "* kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "output_csv_path = '../output/'\n",
    "scores_csv_path = '../depresjon/scores.csv'\n",
    "\n",
    "# load functions in python file with magic command\n",
    "%run ../code/features.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate features\n",
    "features_full = calculate_all_features(df, sunlight_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_full\n",
    "# save to csv\n",
    "features_full.to_csv(output_csv_path + 'features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Female, Male, Both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load functions in python file with magic command\n",
    "%run ../code/model.py\n",
    "\n",
    "# import from csv\n",
    "features_full = pd.read_csv(output_csv_path + 'features.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male dataset shape: (310, 9)\n",
      "Female dataset shape: (383, 9)\n",
      "Both genders dataset shape: (693, 9)\n"
     ]
    }
   ],
   "source": [
    "male, female, both = split_and_prepare_data(features_full)\n",
    "\n",
    "# shapes of the datasets \n",
    "print(f\"Male dataset shape: {male.shape}\")\n",
    "print(f\"Female dataset shape: {female.shape}\")\n",
    "print(f\"Both genders dataset shape: {both.shape}\")\n",
    "\n",
    "# save to csv\n",
    "male.to_csv(output_csv_path + 'male.csv', index=False)\n",
    "female.to_csv(output_csv_path + 'female.csv', index=False)\n",
    "both.to_csv(output_csv_path + 'both.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "TODO - which models were fitted, hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Male dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validation sets\n",
    "X_train, X_validation, y_train, y_validation = validation_data(male)\n",
    "\n",
    "# evaluate models\n",
    "results = evaluate_models(models1, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 models for accuracy:\n",
      "1. QDA: 0.9123367198838898\n",
      "2. LightGBM: 0.8777939042089985\n",
      "3. XGBoost: 0.8666182873730042\n",
      "4. Gradient Boosting: 0.8551523947750364\n",
      "5. Random Forest: 0.8474600870827287\n",
      "\n",
      "Top 5 models for mcc:\n",
      "1. QDA: 0.8304077895913207\n",
      "2. LightGBM: 0.7596469610475839\n",
      "3. XGBoost: 0.7395107715096353\n",
      "4. Gradient Boosting: 0.7167802586438164\n",
      "5. Random Forest: 0.7041118622616565\n",
      "\n",
      "Top 5 models for f1:\n",
      "1. QDA: 0.920036814509143\n",
      "2. LightGBM: 0.887727865354984\n",
      "3. XGBoost: 0.8762607204116637\n",
      "4. Gradient Boosting: 0.8665798045234316\n",
      "5. Random Forest: 0.8626090432513269\n",
      "\n",
      "Top 5 models for training time (fastest to slowest):\n",
      "1. Naive Bayes: 0.02295994758605957 seconds\n",
      "2. SVC linear: 0.02360386848449707 seconds\n",
      "3. Decision Tree: 0.025293779373168946 seconds\n",
      "4. QDA: 0.030854034423828124 seconds\n",
      "5. SVM rbf: 0.03106398582458496 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_models(results, metric='accuracy', top_n=5)\n",
    "#print_top_models(results, top_n=3)\n",
    "print_top_models(results, metric='mcc', top_n=5)\n",
    "print_top_models(results, metric='f1', top_n=5)\n",
    "print_top_models(results, metric='training_time', top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation #1\n",
    "\n",
    "`QDA`, `LightGBM`, `XGBoost`, `GradientBoosting` and `Random Forest` are top five models going to next round.\n",
    "\n",
    "\n",
    "TODO feature importance for each of these models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model selection and evaluation strategy\n",
    "  * either start with many models (garcia) - no hyperparameter\n",
    "  * choose best mcc, f1, accuracy -> top 3 to go into next round\n",
    "  * then look at feature importance -> rationale\n",
    "  * then look at hyperparameter tuning final model\n",
    "  * then look at ensemble??\n",
    "  * repeat for other datasets\n",
    " \n",
    "* model evaluation\n",
    "* metric selection and reason\n",
    "  * `accuracy` - prop of correct predictions; good overall performanced indicator\n",
    "  * `recall (sensitivity)` - prop of actual positives that are correctly identified.  ability to identify all actual cases of depression.  crucial to minimise false negatives that is failing to identify individuals who are depressed.\n",
    "  * `precision` - prop of predicted depression which are correct (true positive predictions among all positive predictions) - important when need to avoid false positives (unnecessary concern, intervention, medication, treatment)\n",
    "   * `F1` - harmonic mean of precision and recall - balance between the two, especially if imbalanced class distribution\n",
    "   * `specificity` - ability to identify non-depression correctly - important to ensure healthy individuals are not misclassified -  measures the proportion of actual negatives that are correctly identified by the mode\n",
    "  * `MCC` - takes into account true adn false positives and negatives.  reliable statistic rate that produces a high score only if the prediction obtained good results in all four matrix categories\n",
    "  * `ROC-AUC - Area Under the Receiver Operating Characteristic Curve`: Evaluates the modelâ€™s ability to discriminate between the classes. A higher AUC indicates better model performance.   ROC-AUC is suitable for depression prediction when you want to evaluate the model's ability to distinguish between depressed and non-depressed individuals across different threshold settings.\n",
    "  * `training time`\n",
    "\n",
    "TODO research Matthews Correlation Coefficient, F1 as key metrics - getting the balance right\n",
    "TODO add metric maths to slides and their importance (contextual)\n",
    "\n",
    "\n",
    "\n",
    "* feature importance analysis - SHAP, Feature Permutation\n",
    "* Hyperparameter tuning\n",
    "* Ensemble models\n",
    "* Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flexible Decision Boundary: Unlike linear classifiers like Logistic Regression or Linear Discriminant Analysis (LDA), QDA can model non-linear decision boundaries between classes. This flexibility allows QDA to capture more complex relationships in the data.\n",
    "Unrestricted Covariance Matrices: QDA allows each class to have its own covariance matrix, whereas Linear Discriminant Analysis (LDA) assumes a common covariance matrix for all classes. This can be beneficial when the classes have different variances or when the relationship between features and classes is complex.\n",
    "Handling Non-Normal Data: Although QDA assumes that the data within each class follows a multivariate normal distribution, it can still perform well even if this assumption is not strictly met, especially if the departure from normality is not severe.\n",
    "Effective with Small Datasets: QDA can be effective with small datasets because it estimates separate covariance matrices for each class, potentially providing better modeling of the underlying data distribution.\n",
    "Robustness to Outliers: QDA can be more robust to outliers compared to linear classifiers like Logistic Regression because it models each class's covariance separately, allowing it to better adapt to the data distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igp5_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
